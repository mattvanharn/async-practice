{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRMZtEj7BOWr"
      },
      "source": [
        "# Compute Gradients with PyTorch\n",
        "\n",
        "Task: compute the gradient of a simple function using PyTorch\n",
        "\n",
        "In our activity on Wednesday, we started working with gradient-based learning. But we had to compute the gradients by a numerical approximation. That is unreliable and inefficient. Today we'll look at how PyTorch's autograd functionality lets us compute that efficiently. (Under the hood this is using backpropagation; we'll learn about that soon."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaSudHc6BOWt"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wfekSerBOWu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import tensor\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNUqMxhaBOWu"
      },
      "source": [
        "We now define a function of two variables:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gy33TuUtBOWv"
      },
      "outputs": [],
      "source": [
        "def square(x):\n",
        "    return x * x\n",
        "\n",
        "def double(x):\n",
        "    return 2 * x\n",
        "\n",
        "def f(x1, x2):\n",
        "    return double(x1) + square(x2) + 5.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-kW03WqBOWv"
      },
      "source": [
        "We evaluate it at a few values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHmJZamHBOWv",
        "outputId": "312e14b4-eba0-47a3-e9eb-7c4ee51ed570"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5.0"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f(0.0, 0.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0D34JOCBOWw",
        "outputId": "ae8c98e5-6801-4e97-bdf4-9df916f44da4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5.2"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f(0.1, 0.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFDokyC7BOWw",
        "outputId": "c97134f9-8dc1-45ed-d0cc-e054a18aa440"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5.01"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f(0.0, 0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dUIVo_qBOWw"
      },
      "source": [
        "## Task 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8IpAvawBOWx"
      },
      "source": [
        "Compute the gradient of `f` with respect to x1, when x1 = 1.0 and x2 = 2.0.\n",
        "\n",
        "Steps:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWDGE_u0BOWx"
      },
      "source": [
        "1. Initialize the input tensors. Tell PyTorch to track their gradients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CtKJvruBOWx"
      },
      "outputs": [],
      "source": [
        "x1 = torch.tensor(1.0, requires_grad=True)\n",
        "x2 = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G347BVlEBOWx"
      },
      "source": [
        "2. Call the function to get the output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QpSDir-zBOWx"
      },
      "outputs": [],
      "source": [
        "result = f(x1, x2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAdDJs4DBOWx"
      },
      "source": [
        "3. Call `backward` on the result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stREJxKIBOWx"
      },
      "outputs": [],
      "source": [
        "result.backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tp5OUPvOBOWy"
      },
      "source": [
        "The gradient is now stored in `x1.grad`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u96xWW8lBOWy",
        "outputId": "d6f5bb4d-c77c-48f1-82dd-ca0067612c0c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(2.)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x1.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ArBHB3vBOWy"
      },
      "source": [
        "## Task 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHvrKc_dBOWy"
      },
      "source": [
        "Compute the gradient of `f` with respect to **x2**, when x1 = 1.0 and x2 = 2.0. (i.e., same point, but evaluating the gradient wrt a different parameter.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKjx9U8zBOWy"
      },
      "outputs": [],
      "source": [
        "x1 = torch.tensor(1.0, requires_grad=True)\n",
        "x2 = torch.tensor(2.0, requires_grad=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYSIW8UUBOWy",
        "outputId": "b9a11cb2-d305-42b5-e1f5-660773a8a17a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(4.)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiOsYEjNBOWy"
      },
      "source": [
        "## Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjsThaSKBOWz"
      },
      "source": [
        "Repeat both tasks above for several other values of `x1` and `x2`. Also look at the definition of `f` and recall what you learned about derivatives in Calculus. Based on that:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hR_ZT-CCBOWz"
      },
      "source": [
        "1. **Write a *simple* mathematical expression that evaluates to the value of x1.grad for any values of x1 and x2.** Use only basic math operations like `+` or `*`; don't use any autograd functionality (like `.backward()`). **The correct solution here is extremely simple!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQF2KefBBOWz"
      },
      "outputs": [],
      "source": [
        "x1_grad = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2vRUMBWBOWz"
      },
      "source": [
        "2. **Write a simple mathematical expression that evaluates to the value of x2.grad for any values of x1 and x2.**\n",
        "\n",
        "Make sure that you understand why this is different from the value of `x1.grad`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_1UuVFaBOWz"
      },
      "outputs": [],
      "source": [
        "x2_grad = ..."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}